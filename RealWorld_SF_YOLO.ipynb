{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install djitellopy opencv-python numpy ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a0526",
   "metadata": {},
   "source": [
    "# Velocity based takeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbf571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO model loaded from /Users/hridayunadkat/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/best.pt\n",
      "Battery level: 86%\n",
      "Press 't' to takeoff, 'q' to land and quit.\n",
      "Drone is now airborne and hovering.\n",
      "Drone moved up 50 cm. Current state: (0, 0, 50)\n",
      "Drone stabilized. Starting adversary detection initialization...\n",
      "YOLO adversary detection active. Bounding box area threshold: 10000 pixels^2\n",
      "Hovering for 5 seconds to initialize adversary position detection...\n",
      "\n",
      "0: 448x640 1 drone, 2017.3ms\n",
      "Speed: 3.0ms preprocess, 2017.3ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "  Calculated adversary depth: 80.0 cm ahead (from bbox area 10168)\n",
      "Adversary position estimate: (80.0, 0.0) [Drone at: (0, 0)]\n",
      "  Detection 1: Adversary detected! Area: 10168 pixels²\n",
      "\n",
      "0: 448x640 1 drone, 1138.8ms\n",
      "Speed: 3.9ms preprocess, 1138.8ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "  Calculated adversary depth: 100.0 cm ahead (from bbox area 7900)\n",
      "Adversary position estimate: (100.0, 0.0) [Drone at: (0, 0)]\n",
      "\n",
      "0: 448x640 1 drone, 1387.3ms\n",
      "Speed: 4.1ms preprocess, 1387.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "  Calculated adversary depth: 100.0 cm ahead (from bbox area 8265)\n",
      "Adversary position estimate: (100.0, 0.0) [Drone at: (0, 0)]\n",
      "Initial detection period complete (3 detections).\n",
      "Initial adversary position estimate: (100.0, 0.0)\n",
      "Movement to (0, 80) SAFE: distance to adversary at (100.0, 0.0) = 128.1 cm >= 50 cm\n",
      "Starting next movement cycle, for now alternative_path_x_taken is False and alternative_path_y_taken is False\n",
      "Movement to (0, 40) SAFE: distance to adversary at (100.0, 0.0) = 107.7 cm >= 50 cm\n",
      "Can move y. Moving towards goal 1: (0, 80), Current: (0.0, 40.0)\n",
      "\n",
      "0: 448x640 1 drone, 1177.0ms\n",
      "Speed: 2.8ms preprocess, 1177.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Adversary position estimate: (100.0, 0.0) [Drone at: (0, 40)]\n",
      "Movement to (0, 80) SAFE: distance to adversary at (100.0, 0.0) = 128.1 cm >= 50 cm\n",
      "Starting next movement cycle, for now alternative_path_x_taken is False and alternative_path_y_taken is False\n",
      "Movement to (0, 80) SAFE: distance to adversary at (100.0, 0.0) = 128.1 cm >= 50 cm\n",
      "Can move y. Moving towards goal 1: (0, 80), Current: (0.0, 80.0)\n",
      "\n",
      "0: 448x640 (no detections), 1228.1ms\n",
      "Speed: 3.7ms preprocess, 1228.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Movement to (0, 80) SAFE: distance to adversary at (100.0, 0.0) = 128.1 cm >= 50 cm\n",
      "Goal 1 reached! (0, 80)\n",
      "\n",
      "0: 448x640 1 drone, 1154.7ms\n",
      "Speed: 2.9ms preprocess, 1154.7ms inference, 6.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Adversary position estimate: (100.0, 0.0) [Drone at: (0, 80)]\n",
      "Movement to (40, 80) SAFE: distance to adversary at (100.0, 0.0) = 100.0 cm >= 50 cm\n",
      "Starting next movement cycle, for now alternative_path_x_taken is False and alternative_path_y_taken is False\n",
      "Movement to (40, 80) SAFE: distance to adversary at (100.0, 0.0) = 100.0 cm >= 50 cm\n",
      "Error occurred: Command 'forward 40' was unsuccessful for 4 tries. Latest response:\t'error Motor stop'\n",
      "Error occurred. Landing the drone.\n"
     ]
    },
    {
     "ename": "TelloException",
     "evalue": "Command 'land' was unsuccessful for 4 tries. Latest response:\t'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTelloException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 595\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 595\u001b[0m     \u001b[43mtello\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmove_step\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# positive x = forward\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Delay after movement\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m check_types(spec, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/tello.py:656\u001b[0m, in \u001b[0;36mTello.move_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fly x cm forward.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03m    x: 20-500\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 656\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m check_types(spec, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/tello.py:621\u001b[0m, in \u001b[0;36mTello.move\u001b[0;34m(self, direction, x)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Tello fly up, down, left, right, forward or back with distance x cm.\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03mUsers would normally call one of the move_x functions instead.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m    direction: up, down, left, right, forward or back\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m    x: 20-500\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_control_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m check_types(spec, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/tello.py:487\u001b[0m, in \u001b[0;36mTello.send_control_command\u001b[0;34m(self, command, timeout)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand attempt #\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m failed for command: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, command))\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_result_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m check_types(spec, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/tello.py:529\u001b[0m, in \u001b[0;36mTello.raise_result_error\u001b[0;34m(self, command, response)\u001b[0m\n\u001b[1;32m    528\u001b[0m tries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_count\n\u001b[0;32m--> 529\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TelloException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was unsuccessful for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m tries. Latest response:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m                      \u001b[38;5;241m.\u001b[39mformat(command, tries, response))\n",
      "\u001b[0;31mTelloException\u001b[0m: Command 'forward 40' was unsuccessful for 4 tries. Latest response:\t'error Motor stop'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTelloException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 744\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drone_in_air:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred. Landing the drone.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 744\u001b[0m         \u001b[43mtello\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mland\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Delay after landing\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m     check_types(spec, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/tello.py:581\u001b[0m, in \u001b[0;36mTello.land\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mland\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    579\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Automatic landing.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_control_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mland\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_flying \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m     check_types(spec, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/tello.py:487\u001b[0m, in \u001b[0;36mTello.send_control_command\u001b[0;34m(self, command, timeout)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand attempt #\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m failed for command: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, command))\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_result_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m     check_types(spec, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/.venv/lib/python3.10/site-packages/djitellopy/tello.py:529\u001b[0m, in \u001b[0;36mTello.raise_result_error\u001b[0;34m(self, command, response)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Used to reaise an error after an unsuccessful command\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03mInternal method, you normally wouldn't call this yourself.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m tries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_count\n\u001b[0;32m--> 529\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TelloException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was unsuccessful for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m tries. Latest response:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m                      \u001b[38;5;241m.\u001b[39mformat(command, tries, response))\n",
      "\u001b[0;31mTelloException\u001b[0m: Command 'land' was unsuccessful for 4 tries. Latest response:\t'error'"
     ]
    }
   ],
   "source": [
    "from djitellopy import Tello\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Suppress INFO and WARNING messages from djitellopy library\n",
    "logging.getLogger('djitellopy').setLevel(logging.ERROR)\n",
    "\n",
    "#####################################\n",
    "# Load YOLO model for adversary detection\n",
    "#####################################\n",
    "model_path = \"/Users/hridayunadkat/Desktop/ECE 532/Final Project/Final Project-Image Classification/doguilmak image classification file/best.pt\"\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"YOLO model not found at {model_path}\")\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(model_path)\n",
    "print(f\"YOLO model loaded from {model_path}\")\n",
    "\n",
    "# Threshold for bounding box area to consider as adversary\n",
    "ADVERSARY_BBOX_AREA_THRESHOLD = 10000  # pixels^2\n",
    "\n",
    "'''\n",
    "World building\n",
    "'''\n",
    "#####################################\n",
    "# Initialization of coordinates\n",
    "#####################################\n",
    "# Coordinate system:\n",
    "#   x: positive = forward, negative = backward\n",
    "#   y: positive = left, negative = right\n",
    "#   z: positive = up, negative = down\n",
    "# Initial starting position of ego drone (at the center of the picnic blanket)\n",
    "ego_x = 0\n",
    "ego_y = 0\n",
    "ego_z = 0\n",
    "\n",
    "# State history: stores full state (x, y, z) at each time step\n",
    "state_history = []  # List of tuples: [(x, y, z), ...]\n",
    "\n",
    "# Flags to track alternative paths (reset at start of each iteration)\n",
    "alternative_path_x_taken = False  # Prohibits x-direction movement temporarily\n",
    "alternative_path_y_taken = False  # Prohibits y-direction movement temporarily\n",
    "\n",
    "#####################################\n",
    "# Adversary detection settings\n",
    "#####################################\n",
    "adversary_active = True  # Set to True to enable adversary avoidance (using YOLO detection)\n",
    "\n",
    "# Estimated adversary position (updated based on bounding box detections)\n",
    "adversary_x_estimate = None  # Estimated x position in world coordinates\n",
    "adversary_y_estimate = None  # Estimated y position in world coordinates\n",
    "adversary_position_initialized = False  # True after first 5-second detection period\n",
    "\n",
    "# Threshold distance for collision avoidance (squared distance: x^2 + y^2)\n",
    "avoidance_radius = 50  # cm threshold\n",
    "adversary_threshold = avoidance_radius**2  # 30^2 = 900 (30 cm threshold)\n",
    "\n",
    "# Bounding box area to distance mapping (pixels² -> cm)\n",
    "# Calibration points:\n",
    "# - 10,000-20,000 pixels² → 80 cm\n",
    "# - 70,000-120,000 pixels² → 40 cm\n",
    "# - > 300,000 pixels² → 5 cm (dangerous)\n",
    "def estimate_distance_from_bbox_area(area):\n",
    "    # Define range endpoints and corresponding distances\n",
    "    area_very_far = 10000\n",
    "    area_far_end = 20000  # Also area_mid_start\n",
    "    distance_far = 80  # cm at area_far_end\n",
    "    \n",
    "    area_mid_end = 50000  # Also area_close_start\n",
    "    distance_mid = 40  # cm at area_mid_end\n",
    "    \n",
    "    area_close_end = 100000  # Also area_danger_start\n",
    "    \n",
    "    area_danger_end = 300000\n",
    "    distance_danger = 5  # cm at area_danger_end\n",
    "    \n",
    "    if area < area_very_far:\n",
    "        return 100  # Very far, assume 100cm\n",
    "    elif area_very_far <= area <= area_far_end:\n",
    "        return distance_far  # Calibrated: 10k-20k = 80cm\n",
    "    elif area_far_end < area < area_mid_end:\n",
    "        # Interpolate between distance_far (at area_far_end) and distance_mid (at area_mid_end)\n",
    "        # slope = (distance_mid - distance_far) / (area_mid_end - area_far_end)\n",
    "        # distance = distance_far + slope * (area - area_far_end)\n",
    "        slope = (distance_mid - distance_far) / (area_mid_end - area_far_end)\n",
    "        distance = distance_far + slope * (area - area_far_end)\n",
    "        return max(distance_mid, min(distance_far, distance))  # Clamp between distance_mid and distance_far\n",
    "    elif area_mid_end <= area <= area_close_end:\n",
    "        return distance_mid  # Calibrated: 70k-120k = 40cm\n",
    "    elif area_close_end < area < area_danger_end:\n",
    "        # Interpolate between distance_mid (at area_close_end) and distance_danger (at area_danger_end)\n",
    "        # slope = (distance_danger - distance_mid) / (area_danger_end - area_close_end)\n",
    "        # distance = distance_mid + slope * (area - area_close_end)\n",
    "        slope = (distance_danger - distance_mid) / (area_danger_end - area_close_end)\n",
    "        distance = distance_mid + slope * (area - area_close_end)\n",
    "        return max(distance_danger, min(distance_mid, distance))  # Clamp between distance_danger and distance_mid\n",
    "    else:  # area >= area_danger_end\n",
    "        return distance_danger  # Dangerous: >=300k = 5cm\n",
    "\n",
    "#####################################\n",
    "# Goal tracking\n",
    "#####################################\n",
    "goal_index = 0\n",
    "goals = [\n",
    "    # (20, 0),   # Goal 1: Forward\n",
    "    # (20, 20),  # Goal 2: Forward and left\n",
    "    # (20, -20)   # Goal 3: Forward and Right Two Steps\n",
    "\n",
    "    # (0, 20),   # Goal 1: Left\n",
    "    # (20, 20),  # Goal 2: Left, then move Forward\n",
    "    # (20, -20)   # Goal 3: Left, Forward, then Right Two Steps\n",
    "\n",
    "    (0, 80),   # Goal 1: Left\n",
    "    (40, 80),  # Goal 2: Left, then move Forward\n",
    "    (40, -80)   # Goal 3: Left, Forward, then Right Two Steps\n",
    "]\n",
    "\n",
    "'''\n",
    "Drone building\n",
    "'''\n",
    "#####################################\n",
    "# Initialization of motion params\n",
    "#####################################\n",
    "upward_initialization =50 #20 cm is the minimum\n",
    "move_step = 40\n",
    "\n",
    "#####################################\n",
    "# Initialization of drone\n",
    "#####################################\n",
    "tello = Tello()\n",
    "#print(\"Connecting to Tello...\")\n",
    "tello.connect()\n",
    "print(f\"Battery level: {tello.get_battery()}%\")\n",
    "tello.streamon()\n",
    "\n",
    "print(\"Press 't' to takeoff, 'q' to land and quit.\")\n",
    "drone_in_air = False\n",
    "\n",
    "#####################################\n",
    "# Definitions\n",
    "#####################################\n",
    "def estimate_adversary_position_from_bbox(frame, box, current_ego_x, current_ego_y, is_initial_period=False):\n",
    "    global adversary_x_estimate, adversary_y_estimate\n",
    "    \n",
    "    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "    box_area = (x2 - x1) * (y2 - y1)\n",
    "    \n",
    "    # Estimate distance (depth) from bounding box area\n",
    "    distance_cm = estimate_distance_from_bbox_area(box_area)\n",
    "    \n",
    "    # Adversary is assumed to be directly ahead (y = 0 relative to drone) and stationary\n",
    "    # Depth (x) calculation:\n",
    "    # - During initial period: calculate from bounding box area\n",
    "    # - After initial period: keep the same depth (adversary is stationary)\n",
    "    if is_initial_period or adversary_x_estimate is None:\n",
    "        # Calculate depth: adversary is ahead by distance_cm\n",
    "        adversary_x_estimate = current_ego_x + distance_cm\n",
    "        # Adversary y is same as drone y (directly ahead, y=0 relative)\n",
    "        adversary_y_estimate = current_ego_y\n",
    "        print(f\"  Calculated adversary depth: {distance_cm:.1f} cm ahead (from bbox area {box_area:.0f})\")\n",
    "    else:\n",
    "        # After initial period: adversary is stationary\n",
    "        # Keep the same x (depth) - don't recalculate\n",
    "        # Keep y = 0 (same as initial y, adversary doesn't move)\n",
    "        # adversary_x_estimate and adversary_y_estimate stay constant\n",
    "        pass\n",
    "    \n",
    "    return adversary_x_estimate, adversary_y_estimate\n",
    "\n",
    "def detect_adversary_yolo(frame, current_ego_x=None, current_ego_y=None, update_position=False, is_initial_period=False):\n",
    "    if frame is None:\n",
    "        return False, None, 0\n",
    "    \n",
    "    # Run YOLO detection\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Check for bounding boxes with area > threshold\n",
    "    boxes = results[0].boxes\n",
    "    adversary_detected = False\n",
    "    max_area = 0\n",
    "    largest_box = None\n",
    "    \n",
    "    if len(boxes) > 0:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            box_area = (x2 - x1) * (y2 - y1)\n",
    "            if box_area > max_area:\n",
    "                max_area = box_area\n",
    "                largest_box = box\n",
    "            if box_area > ADVERSARY_BBOX_AREA_THRESHOLD:\n",
    "                adversary_detected = True\n",
    "    \n",
    "    # Update adversary position estimate if requested and we have a detection\n",
    "    if update_position and largest_box is not None and current_ego_x is not None and current_ego_y is not None:\n",
    "        adv_x, adv_y = estimate_adversary_position_from_bbox(frame, largest_box, current_ego_x, current_ego_y, is_initial_period=is_initial_period)\n",
    "        # Print position estimate for each detection\n",
    "        print(f\"Adversary position estimate: ({adv_x:.1f}, {adv_y:.1f}) [Drone at: ({current_ego_x}, {current_ego_y})]\")\n",
    "    \n",
    "    # Get annotated frame (always plot to show detections, even if below threshold)\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    return adversary_detected, annotated_frame, max_area\n",
    "\n",
    "def compute_switching_filter(new_x, new_y, current_frame=None, current_ego_x=None, current_ego_y=None):\n",
    "    if not adversary_active:\n",
    "        return False\n",
    "    \n",
    "    # If we don't have an estimated adversary position yet, movement is safe\n",
    "    if adversary_x_estimate is None or adversary_y_estimate is None:\n",
    "        return False\n",
    "    \n",
    "    # Calculate squared distance from intended new position to estimated adversary position\n",
    "    dist_to_adversary_sq = (new_x - adversary_x_estimate)**2 + (new_y - adversary_y_estimate)**2\n",
    "    \n",
    "    # Block if within avoidance radius (30 cm)\n",
    "    is_blocking = dist_to_adversary_sq < adversary_threshold\n",
    "    \n",
    "    if is_blocking:\n",
    "        distance = np.sqrt(dist_to_adversary_sq)\n",
    "        print(f\"Movement to ({new_x}, {new_y}) BLOCKED: too close to adversary at ({adversary_x_estimate:.1f}, {adversary_y_estimate:.1f}), distance = {distance:.1f} cm < {avoidance_radius} cm\")\n",
    "    else:\n",
    "        distance = np.sqrt(dist_to_adversary_sq)\n",
    "        print(f\"Movement to ({new_x}, {new_y}) SAFE: distance to adversary at ({adversary_x_estimate:.1f}, {adversary_y_estimate:.1f}) = {distance:.1f} cm >= {avoidance_radius} cm\")\n",
    "    \n",
    "    return is_blocking\n",
    "\n",
    "def find_alternative_path(current_x, current_y, goal_x, goal_y, blocked_direction='x', current_frame=None):\n",
    "    dx = goal_x - current_x  # positive = need to go forward, negative = need to go backward\n",
    "    dy = goal_y - current_y  # positive = need to go left, negative = need to go right\n",
    "    \n",
    "    alternatives = []\n",
    "    \n",
    "    # If x-direction is blocked, try moving in y-direction\n",
    "    if blocked_direction == 'x':\n",
    "        # First try moving in the y-direction that helps reach the goal (if dy != 0)\n",
    "        if dy != 0:\n",
    "            # Try moving in the direction of the goal's y component\n",
    "            alt_x = current_x\n",
    "            alt_y = current_y + move_step if dy > 0 else current_y - move_step\n",
    "            if not compute_switching_filter(alt_x, alt_y, current_frame):\n",
    "                alternatives.append((alt_x, alt_y))\n",
    "        \n",
    "        # If that doesn't work, try the opposite y direction\n",
    "        if not alternatives and dy != 0:\n",
    "            alt_x = current_x\n",
    "            alt_y = current_y - move_step if dy > 0 else current_y + move_step\n",
    "            if not compute_switching_filter(alt_x, alt_y, current_frame):\n",
    "                alternatives.append((alt_x, alt_y))\n",
    "        \n",
    "        # If that doesn't work or dy == 0, try left and right (to go around obstacle)\n",
    "        if not alternatives:\n",
    "            # Try left first (positive y)\n",
    "            alt_x = current_x\n",
    "            alt_y = current_y + move_step\n",
    "            if not compute_switching_filter(alt_x, alt_y, current_frame):\n",
    "                alternatives.append((alt_x, alt_y))\n",
    "        \n",
    "        # If left doesn't work, try right\n",
    "        if not alternatives:\n",
    "            alt_x = current_x\n",
    "            alt_y = current_y - move_step\n",
    "            if not compute_switching_filter(alt_x, alt_y, current_frame):\n",
    "                alternatives.append((alt_x, alt_y))\n",
    "    \n",
    "    # If y-direction is blocked, try moving in x-direction\n",
    "    elif blocked_direction == 'y':\n",
    "        # First try moving in the x-direction that helps reach the goal (if dx != 0)\n",
    "        if dx != 0:\n",
    "            # Try moving in the direction of the goal's x component\n",
    "            alt_x = current_x + move_step if dx > 0 else current_x - move_step\n",
    "            alt_y = current_y\n",
    "            if not compute_switching_filter(alt_x, alt_y, current_frame):\n",
    "                alternatives.append((alt_x, alt_y))\n",
    "        \n",
    "        # If that doesn't work or dx == 0, try forward and backward (to go around obstacle)\n",
    "        if not alternatives:\n",
    "            # Try forward first (positive x)\n",
    "            alt_x = current_x + move_step\n",
    "            alt_y = current_y\n",
    "            if not compute_switching_filter(alt_x, alt_y, current_frame):\n",
    "                alternatives.append((alt_x, alt_y))\n",
    "        \n",
    "        # If forward doesn't work, try backward\n",
    "        if not alternatives:\n",
    "            alt_x = current_x - move_step\n",
    "            alt_y = current_y\n",
    "            if not compute_switching_filter(alt_x, alt_y, current_frame):\n",
    "                alternatives.append((alt_x, alt_y))\n",
    "    \n",
    "    # Return the first safe alternative found (prioritized by goal direction)\n",
    "    if alternatives:\n",
    "        return alternatives[0]\n",
    "    \n",
    "    return None  # No safe alternative path found\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Takeoff\n",
    "'''\n",
    "#####################################\n",
    "# Drone maneuverance after takeoff\n",
    "#####################################\n",
    "try:\n",
    "    # Record initial state before loop starts\n",
    "    state_history.append((ego_x, ego_y, ego_z))\n",
    "    \n",
    "    while True:\n",
    "        frame = tello.get_frame_read().frame\n",
    "        if frame is None:\n",
    "            continue\n",
    "        frame = cv2.resize(frame, (720, 480))\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # Only run YOLO detection when drone is in the air (to avoid blocking key presses before takeoff)\n",
    "        if drone_in_air and adversary_active:\n",
    "            # Run YOLO detection on frame (update position estimate during flight)\n",
    "            # After initial period, depth is kept constant (adversary is stationary)\n",
    "            adversary_detected, annotated_frame, max_bbox_area = detect_adversary_yolo(\n",
    "                frame, \n",
    "                current_ego_x=ego_x, \n",
    "                current_ego_y=ego_y, \n",
    "                update_position=True,\n",
    "                is_initial_period=False  # After initialization, depth stays constant\n",
    "            )\n",
    "            \n",
    "            # Display the annotated frame with YOLO detections\n",
    "            display_frame = annotated_frame if annotated_frame is not None else frame.copy()\n",
    "            \n",
    "            # Add text overlay showing detection status\n",
    "            if adversary_detected:\n",
    "                cv2.putText(display_frame, f\"ADVERSARY DETECTED! Area: {max_bbox_area:.0f}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                if adversary_x_estimate is not None and adversary_y_estimate is not None:\n",
    "                    cv2.putText(display_frame, f\"Est. pos: ({adversary_x_estimate:.0f}, {adversary_y_estimate:.0f})\", \n",
    "                               (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "            else:\n",
    "                if max_bbox_area > 0:\n",
    "                    cv2.putText(display_frame, f\"Detection below threshold (area: {max_bbox_area:.0f})\", \n",
    "                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                else:\n",
    "                    cv2.putText(display_frame, f\"No detections\", \n",
    "                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        else:\n",
    "            # Before takeoff, just show raw frame (no YOLO detection to keep loop fast)\n",
    "            display_frame = frame.copy()\n",
    "            cv2.putText(display_frame, \"Press 't' to takeoff\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Tello Tracking Feed\", display_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Controls for drone\n",
    "        if key == ord('t') and not drone_in_air:\n",
    "            tello.takeoff()\n",
    "            drone_in_air = True\n",
    "            print(\"Drone is now airborne and hovering.\")\n",
    "            tello.move_up(upward_initialization)  # move up 30 cm after takeoff\n",
    "            ego_z += upward_initialization\n",
    "            state_history.append((ego_x, ego_y, ego_z))  # Record state after movement\n",
    "            print(f\"Drone moved up {upward_initialization} cm. Current state: ({ego_x}, {ego_y}, {ego_z})\")\n",
    "            \n",
    "            # Wait a moment for drone to stabilize after upward movement\n",
    "            time.sleep(1.0)\n",
    "            print(\"Drone stabilized. Starting adversary detection initialization...\")\n",
    "            \n",
    "            if adversary_active:\n",
    "                print(f\"YOLO adversary detection active. Bounding box area threshold: {ADVERSARY_BBOX_AREA_THRESHOLD} pixels^2\")\n",
    "                print(\"Hovering for 5 seconds to initialize adversary position detection...\")\n",
    "                \n",
    "                # Hover for 5 seconds and perform detections to estimate adversary position\n",
    "                detection_start_time = time.time()\n",
    "                detection_count = 0\n",
    "                while time.time() - detection_start_time < 5.0:\n",
    "                    # Get frame for detection\n",
    "                    detection_frame = tello.get_frame_read().frame\n",
    "                    if detection_frame is not None:\n",
    "                        detection_frame = cv2.resize(detection_frame, (720, 480))\n",
    "                        # Run detection with position update enabled (is_initial_period=True)\n",
    "                        adv_detected, annotated_frame, max_area = detect_adversary_yolo(\n",
    "                            detection_frame, \n",
    "                            current_ego_x=ego_x, \n",
    "                            current_ego_y=ego_y, \n",
    "                            update_position=True,\n",
    "                            is_initial_period=True\n",
    "                        )\n",
    "                        detection_count += 1\n",
    "                        \n",
    "                        # Display the annotated frame with detection info\n",
    "                        display_frame = annotated_frame if annotated_frame is not None else detection_frame.copy()\n",
    "                        elapsed = time.time() - detection_start_time\n",
    "                        cv2.putText(display_frame, f\"Initial Detection Period: {elapsed:.1f}s / 5.0s\", \n",
    "                                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                        if adv_detected:\n",
    "                            cv2.putText(display_frame, f\"ADVERSARY DETECTED! Area: {max_area:.0f}\", \n",
    "                                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                            if adversary_x_estimate is not None and adversary_y_estimate is not None:\n",
    "                                cv2.putText(display_frame, f\"Est. pos: ({adversary_x_estimate:.0f}, {adversary_y_estimate:.0f})\", \n",
    "                                           (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                        cv2.imshow(\"Tello Tracking Feed\", display_frame)\n",
    "                        cv2.waitKey(1)  # Update display\n",
    "                        \n",
    "                        if adv_detected:\n",
    "                            print(f\"  Detection {detection_count}: Adversary detected! Area: {max_area:.0f} pixels²\")\n",
    "                    \n",
    "                    time.sleep(0.1)  # Small delay between detections\n",
    "                \n",
    "                adversary_position_initialized = True\n",
    "                print(f\"Initial detection period complete ({detection_count} detections).\")\n",
    "                if adversary_x_estimate is not None and adversary_y_estimate is not None:\n",
    "                    print(f\"Initial adversary position estimate: ({adversary_x_estimate:.1f}, {adversary_y_estimate:.1f})\")\n",
    "                else:\n",
    "                    print(\"No adversary detected during initialization period.\")\n",
    "\n",
    "        # if key == ord('t') and not drone_in_air:\n",
    "        #     tello.takeoff()\n",
    "        #     time.sleep(2)  # Delay after takeoff to allow drone to stabilize\n",
    "        #     drone_in_air = True\n",
    "        #     print(\"Drone is now airborne.\")\n",
    "            \n",
    "        #     # Gradual takeoff using velocity control\n",
    "        #     target_height = 30  # cm you want to reach (minimum safe height)\n",
    "        #     hover_speed = 10    # cm/s (upward velocity)\n",
    "        #     steps = int(target_height / hover_speed)\n",
    "            \n",
    "        #     for _ in range(steps):\n",
    "        #         tello.send_rc_control(0, 0, hover_speed, 0)  # (left-right, forward-back, up-down, yaw)\n",
    "        #         ego_z += hover_speed\n",
    "        #         state_history.append((ego_x, ego_y, ego_z))\n",
    "        #         time.sleep(1)  # sleep 1 second per step\n",
    "\n",
    "        #     # Stop upward motion and hover\n",
    "        #     #tello.send_rc_control(0, 0, 0, 0)\n",
    "        #     time.sleep(0.5)  # Delay after stopping motion\n",
    "        #     print(f\"Reached hover height: {ego_z} cm\")\n",
    "        #     if adversary_active:\n",
    "        #         print(f\"YOLO adversary detection active. Bounding box area threshold: {ADVERSARY_BBOX_AREA_THRESHOLD} pixels^2\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # drone movement based on goals\n",
    "        if drone_in_air and goal_index < len(goals):\n",
    "            target_x, target_y = goals[goal_index]\n",
    "            \n",
    "            # Check if goal is blocked by adversary (switching-based control)\n",
    "            if adversary_active and compute_switching_filter(target_x, target_y, frame):\n",
    "                print(f\"Goal {goal_index + 1} at ({target_x}, {target_y}) is BLOCKED by adversary (YOLO detection)\")\n",
    "                print(f\"Skipping goal {goal_index + 1} and moving to next goal...\")\n",
    "                goal_index += 1\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "                # Check if we've processed all goals (no linked list - don't return to skipped goals)\n",
    "                if goal_index >= len(goals):\n",
    "                    print(\"All goals processed! Landing the drone...\")\n",
    "                    if drone_in_air:\n",
    "                        tello.land()\n",
    "                        time.sleep(3)  # Delay after landing\n",
    "                        state_history.append((ego_x, ego_y, ego_z))  # Record final state\n",
    "                        print(\"Drone has landed.\")\n",
    "                        print(f\"Final state: ({ego_x}, {ego_y}, {ego_z})\")\n",
    "                        print(f\"Total states recorded: {len(state_history)}\")\n",
    "                    break\n",
    "                continue\n",
    "            \n",
    "            # Calculate distance to current goal\n",
    "            dx = target_x - ego_x\n",
    "            dy = target_y - ego_y\n",
    "            distance_to_goal = np.sqrt(dx**2 + dy**2)\n",
    "            \n",
    "            # Threshold for considering goal reached (within 5 cm)\n",
    "            goal_threshold = 5\n",
    "            \n",
    "            if distance_to_goal > goal_threshold:\n",
    "                movement_made = False\n",
    "\n",
    "                # Initialize flags for this movement cycle (reset at end of each iteration)\n",
    "                #alternative_path_x_taken = False\n",
    "                #alternative_path_y_taken = False\n",
    "                print(f\"Starting next movement cycle, for now alternative_path_x_taken is {alternative_path_x_taken} and alternative_path_y_taken is {alternative_path_y_taken}\")\n",
    "\n",
    "                # Move in x direction first (only if not prohibited by alternative path)\n",
    "                if abs(dx) > 0 and not alternative_path_x_taken:\n",
    "                    # Calculate potential new position\n",
    "                    new_x = ego_x + move_step if dx > 0 else ego_x - move_step\n",
    "                    new_y = ego_y  # y stays the same for x movement\n",
    "                    \n",
    "                    # Check if movement is safe (if adversary is active)\n",
    "                    can_move_x = True\n",
    "                    if adversary_active:\n",
    "                        if compute_switching_filter(new_x, new_y, frame):\n",
    "                            can_move_x = False\n",
    "                            print(f\"CANT MOVE TOWARDS GOAL {goal_index + 1} at {goals[goal_index]} IN X DIRECTION, ADVERSARY BLOCKING (YOLO)\")\n",
    "                            # Try alternative path (x-direction is blocked, so try y-direction)\n",
    "                            alt_waypoint = find_alternative_path(ego_x, ego_y, target_x, target_y, blocked_direction='x', current_frame=frame)\n",
    "                            if alt_waypoint:\n",
    "                                alt_x, alt_y = alt_waypoint\n",
    "                                alt_dx = alt_x - ego_x\n",
    "                                alt_dy = alt_y - ego_y\n",
    "                                # Print and execute alternative movement\n",
    "                                if abs(alt_dy) > 0:\n",
    "                                    # Alternative path moves in y direction\n",
    "                                    if alt_dy > 0:\n",
    "                                        print(f\"Taking alternative path: Moving left to ({alt_x:.1f}, {alt_y:.1f})\")\n",
    "                                        tello.move_left(move_step)  # positive y = left\n",
    "                                        time.sleep(0.5)  # Delay after movement\n",
    "                                        ego_y += move_step\n",
    "                                    else:\n",
    "                                        print(f\"Taking alternative path: Moving right to ({alt_x:.1f}, {alt_y:.1f})\")\n",
    "                                        tello.move_right(move_step)  # negative y = right\n",
    "                                        time.sleep(0.5)  # Delay after movement\n",
    "                                        ego_y -= move_step\n",
    "                                    alternative_path_y_taken = True  # Prohibit y-direction temporarily\n",
    "                                elif abs(alt_dx) > 0:\n",
    "                                    # Alternative path moves in x direction\n",
    "                                    if alt_dx > 0:\n",
    "                                        print(f\"Taking alternative path: Moving forward to ({alt_x:.1f}, {alt_y:.1f})\")\n",
    "                                        tello.move_forward(move_step)  # positive x = forward\n",
    "                                        time.sleep(0.5)  # Delay after movement\n",
    "                                        ego_x += move_step\n",
    "                                    else:\n",
    "                                        print(f\"Taking alternative path: Moving back to ({alt_x:.1f}, {alt_y:.1f})\")\n",
    "                                        tello.move_back(move_step)  # negative x = backward\n",
    "                                        time.sleep(0.5)  # Delay after movement\n",
    "                                        ego_x -= move_step\n",
    "                                    alternative_path_x_taken = True  # Prohibit x-direction temporarily\n",
    "                                state_history.append((ego_x, ego_y, ego_z))\n",
    "                                print(f\"Alternative path taken. Current position: ({ego_x:.1f}, {ego_y:.1f}); alternative_path_x_taken is {alternative_path_x_taken}, alternative_path_y_taken is {alternative_path_y_taken} \")\n",
    "                                movement_made = True\n",
    "                                time.sleep(0.5)\n",
    "                            else:\n",
    "                                print(f\"No alternative path found for X movement. Trying Y direction or skipping...\")\n",
    "                    \n",
    "                    # Execute movement if safe\n",
    "                    if can_move_x and not alternative_path_x_taken:\n",
    "                        if dx > 0:\n",
    "                            tello.move_forward(move_step)  # positive x = forward\n",
    "                            time.sleep(0.5)  # Delay after movement\n",
    "                        else:\n",
    "                            tello.move_back(move_step)  # negative x = backward\n",
    "                            time.sleep(0.5)  # Delay after movement\n",
    "                        ego_x = new_x\n",
    "                        state_history.append((ego_x, ego_y, ego_z))\n",
    "                        print(f\"Can move x. Moving towards goal {goal_index + 1}: ({target_x}, {target_y}), Current: ({ego_x:.1f}, {ego_y:.1f})\")\n",
    "                        movement_made = True\n",
    "                        time.sleep(0.5)\n",
    "\n",
    "                # Then move in y direction (only if not prohibited and x movement didn't happen or was successful)\n",
    "                if abs(dy) > 0 and not alternative_path_y_taken and (not movement_made or abs(dx) == 0 or alternative_path_x_taken):\n",
    "                    # Calculate potential new position\n",
    "                    new_x = ego_x  # x stays the same for y movement\n",
    "                    new_y = ego_y + move_step if dy > 0 else ego_y - move_step\n",
    "                    \n",
    "                    # Check if movement is safe (if adversary is active)\n",
    "                    can_move_y = True\n",
    "                    if adversary_active:\n",
    "                        if compute_switching_filter(new_x, new_y, frame):\n",
    "                            can_move_y = False\n",
    "                            print(f\"CANT MOVE TOWARDS GOAL {goal_index + 1} at {goals[goal_index]} IN Y DIRECTION, ADVERSARY BLOCKING (YOLO)\")\n",
    "                            # Try alternative path (y-direction is blocked, so try x-direction)\n",
    "                            alt_waypoint = find_alternative_path(ego_x, ego_y, target_x, target_y, blocked_direction='y', current_frame=frame)\n",
    "                            if alt_waypoint:\n",
    "                                alt_x, alt_y = alt_waypoint\n",
    "                                alt_dx = alt_x - ego_x\n",
    "                                alt_dy = alt_y - ego_y\n",
    "                                # Print and execute alternative movement\n",
    "                                if abs(alt_dx) > 0:\n",
    "                                    # Alternative path moves in x direction\n",
    "                                    if alt_dx > 0:\n",
    "                                        print(f\"Taking alternative path: Moving forward to ({alt_x:.1f}, {alt_y:.1f})\")\n",
    "                                        tello.move_forward(move_step)  # positive x = forward\n",
    "                                        time.sleep(0.5)  # Delay after movement\n",
    "                                        ego_x += move_step\n",
    "                                    else:\n",
    "                                        print(f\"Taking alternative path: Moving back to ({alt_x:.1f}, {alt_y:.1f})\")\n",
    "                                        tello.move_back(move_step)  # negative x = backward\n",
    "                                        time.sleep(0.5)  # Delay after movement\n",
    "                                        ego_x -= move_step\n",
    "                                    alternative_path_x_taken = True  # Prohibit x-direction temporarily\n",
    "                                elif abs(alt_dy) > 0:\n",
    "                                    # Alternative path moves in y direction\n",
    "                                    if alt_dy > 0:\n",
    "                                        print(f\"Taking alternative path: Moving left to ({alt_x:.1f}, {alt_y:.1f})\")\n",
    "                                        tello.move_left(move_step)  # positive y = left\n",
    "                                        time.sleep(0.5)  # Delay after movement\n",
    "                                        ego_y += move_stepz\n",
    "                                    else:\n",
    "                                        print(f\"Taking alternative path: Moving right to ({alt_x:.1f}, {alt_y:.1f})\")\n",
    "                                        tello.move_right(move_step)  # negative y = right\n",
    "                                        time.sleep(0.5)  # Delay after movement\n",
    "                                        ego_y -= move_step\n",
    "                                    alternative_path_y_taken = True  # Prohibit y-direction temporarily\n",
    "                                state_history.append((ego_x, ego_y, ego_z))\n",
    "                                print(f\"Alternative path taken. Current position: ({ego_x:.1f}, {ego_y:.1f}); alternative_path_x_taken is {alternative_path_x_taken}, alternative_path_y_taken is {alternative_path_y_taken}\")\n",
    "                                movement_made = True\n",
    "                                time.sleep(0.5)\n",
    "                            else:\n",
    "                                print(f\"No alternative path found for Y movement.\")\n",
    "                    \n",
    "                    # Execute movement if safe\n",
    "                    if can_move_y and not alternative_path_y_taken:\n",
    "                        if dy > 0:\n",
    "                            tello.move_left(move_step)  # positive y = left\n",
    "                            time.sleep(0.5)  # Delay after movement\n",
    "                        else:\n",
    "                            tello.move_right(move_step)  # negative y = right\n",
    "                            time.sleep(0.5)  # Delay after movement\n",
    "                        ego_y = new_y\n",
    "                        state_history.append((ego_x, ego_y, ego_z))\n",
    "                        print(f\"Can move y. Moving towards goal {goal_index + 1}: ({target_x}, {target_y}), Current: ({ego_x:.1f}, {ego_y:.1f})\")\n",
    "                        movement_made = True\n",
    "                        time.sleep(0.5)\n",
    "\n",
    "                #Strategic reset of flags\n",
    "                if alternative_path_x_taken:\n",
    "                    if ego_y == target_y:\n",
    "                        alternative_path_x_taken = False\n",
    "                        print(\"Resetting alternative_path_x_taken to False, since we are at the target y coordinate\")\n",
    "\n",
    "                if alternative_path_y_taken:\n",
    "                    if ego_x == target_x:\n",
    "                        alternative_path_y_taken = False\n",
    "                        print(\"Resetting alternative_path_y_taken to False, since we are at the target x coordinate\")\n",
    "\n",
    "\n",
    "                # If completely stuck (can't move in either direction and no alternative path)\n",
    "                if not movement_made and adversary_active:\n",
    "                    print(f\"STUCK: Cannot move towards goal {goal_index + 1} from current position ({ego_x}, {ego_y})\")\n",
    "                    print(f\"Skipping goal {goal_index + 1} and moving to next goal...\")\n",
    "                    goal_index += 1\n",
    "                    time.sleep(0.5)\n",
    "                    \n",
    "                    # Check if we've processed all goals\n",
    "                    if goal_index >= len(goals):\n",
    "                        print(\"All goals processed! Landing the drone...\")\n",
    "                        if drone_in_air:\n",
    "                            tello.land()\n",
    "                            time.sleep(3)  # Delay after landing\n",
    "                            state_history.append((ego_x, ego_y, ego_z))  # Record final state\n",
    "                            print(\"Drone has landed.\")\n",
    "                            print(f\"Final state: ({ego_x}, {ego_y}, {ego_z})\")\n",
    "                            print(f\"Total states recorded: {len(state_history)}\")\n",
    "                        break\n",
    "\n",
    "            \n",
    "            else:\n",
    "                # Goal reached\n",
    "                print(f\"Goal {goal_index + 1} reached! ({target_x}, {target_y})\")\n",
    "                goal_index += 1\n",
    "                time.sleep(1)\n",
    "                \n",
    "                if goal_index >= len(goals):\n",
    "                    print(\"All goals processed! Landing the drone...\")\n",
    "                    if drone_in_air:\n",
    "                        tello.land()\n",
    "                        time.sleep(3)  # Delay after landing\n",
    "                        state_history.append((ego_x, ego_y, ego_z))  # Record final state\n",
    "                        print(\"Drone has landed.\")\n",
    "                        print(f\"Final state: ({ego_x}, {ego_y}, {ego_z})\")\n",
    "                        print(f\"Total states recorded: {len(state_history)}\")\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Landing control\n",
    "        if key == ord('q'):\n",
    "            if drone_in_air:\n",
    "                tello.land()\n",
    "                time.sleep(3)  # Delay after landing to allow drone to settle\n",
    "                state_history.append((ego_x, ego_y, ego_z))  # Record final state before landing\n",
    "                print(\"Drone has landed.\")\n",
    "                print(f\"Final state: ({ego_x}, {ego_y}, {ego_z})\")\n",
    "                print(f\"Total states recorded: {len(state_history)}\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Landing the drone / finish program\n",
    "#####################################\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    if drone_in_air:\n",
    "        print(\"Error occurred. Landing the drone.\")\n",
    "        tello.land()\n",
    "        time.sleep(3)  # Delay after landing\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Keyboard Interrupt received. Landing the drone.\")\n",
    "    if drone_in_air:\n",
    "        tello.land()\n",
    "        time.sleep(3)  # Delay after landing\n",
    "    tello.streamoff()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "finally:\n",
    "    tello.streamoff()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
